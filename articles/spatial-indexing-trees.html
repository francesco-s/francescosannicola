<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta
      name="description"
      content="This post explores three fundamental spatial indexing structures, KDTrees, BallTrees, and the STR-packed R-tree, moving beyond scikit-learn imports to understand their mathematical backbones."
    />

    <meta
      name="keywords"
      content="spatial indexing, kdtree, balltree, rtree, strtree, nearest neighbor search, data structures, algorithms, geospatial"
    />
    <meta name="author" content="Francesco Sannicola" />
    <meta
      property="og:title"
      content="Spatial Indexing Trees: KDTree, BallTree, and STRtree - Francesco Sannicola"
    />
    <meta
      property="og:description"
      content="Explore spatial indexing structures from mathematical foundations to implementation: KDTree, BallTree, and STR-packed R-tree."
    />
    <meta
      property="og:url"
      content="https://www.francescosannicola.com/articles"
    />
    <meta property="og:type" content="website" />
    <meta property="og:image" content="./assets/francescosannicola.jpg" />
    <title>Spatial Indexing Trees - Francesco Sannicola</title>
    <link rel="icon" type="image/x-icon" href="../favicon.ico" />
    <script
      type="text/javascript"
      async
      src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"
    ></script>

    <link rel="stylesheet" type="text/css" href="../style.css" />
    <link
      href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css"
      rel="stylesheet"
    />
    <link
      href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css"
      rel="stylesheet"
    />
  </head>
  <body>
    <div class="main-container">
      <div class="left-column">
        <header>
          <div class="header-left">
            <h1>Francesco Sannicola</h1>
            <h4 class="role">Machine Learning | Software Engineering</h4>
          </div>

          <div class="header-right">
            <div class="contact-info">
              <a href="../resume.pdf" target="_blank" aria-label="View Resume">
                <svg
                  fill="#000000"
                  version="1.1"
                  id="Capa_1"
                  xmlns="http://www.w3.org/2000/svg"
                  xmlns:xlink="http://www.w3.org/1999/xlink"
                  width="18"
                  height="18"
                  viewBox="0 0 45.057 45.057"
                  xml:space="preserve"
                >
                  <title>Resume</title>
                  <g>
                    <g id="_x35_8_24_">
                      <g>
                        <path
                          d="M19.558,25.389c-0.067,0.176-0.155,0.328-0.264,0.455c-0.108,0.129-0.24,0.229-0.396,0.301
                                       c-0.156,0.072-0.347,0.107-0.57,0.107c-0.313,0-0.572-0.068-0.78-0.203c-0.208-0.137-0.374-0.316-0.498-0.541
                                       c-0.124-0.223-0.214-0.477-0.27-0.756c-0.057-0.279-0.084-0.564-0.084-0.852c0-0.289,0.027-0.572,0.084-0.853
                                       c0.056-0.281,0.146-0.533,0.27-0.756c0.124-0.225,0.29-0.404,0.498-0.541c0.208-0.137,0.468-0.203,0.78-0.203
                                       c0.271,0,0.494,0.051,0.666,0.154c0.172,0.105,0.31,0.225,0.414,0.361c0.104,0.137,0.176,0.273,0.216,0.414
                                       c0.04,0.139,0.068,0.25,0.084,0.33h2.568c-0.112-1.08-0.49-1.914-1.135-2.502c-0.644-0.588-1.558-0.887-2.741-0.895
                                       c-0.664,0-1.263,0.107-1.794,0.324c-0.532,0.215-0.988,0.52-1.368,0.912c-0.38,0.392-0.672,0.863-0.876,1.416
                                       c-0.204,0.551-0.307,1.165-0.307,1.836c0,0.631,0.097,1.223,0.288,1.77c0.192,0.549,0.475,1.021,0.847,1.422
                                       s0.825,0.717,1.361,0.949c0.536,0.23,1.152,0.348,1.849,0.348c0.624,0,1.18-0.105,1.668-0.312
                                       c0.487-0.209,0.897-0.482,1.229-0.822s0.584-0.723,0.756-1.146c0.172-0.422,0.259-0.852,0.259-1.283h-2.593
                                       C19.68,25.023,19.627,25.214,19.558,25.389z"
                        />
                        <polygon
                          points="26.62,24.812 26.596,24.812 25.192,19.616 22.528,19.616 25.084,28.184 28.036,28.184 30.713,19.616 28,19.616"
                        />
                        <path
                          d="M33.431,0H5.179v45.057h34.699V6.251L33.431,0z M36.878,42.056H8.179V3h23.706v4.76h4.992L36.878,42.056L36.878,42.056z"
                        />
                      </g>
                    </g>
                  </g>
                </svg>
                <span class="contact-label">Resume</span>
              </a>

              <a
                href="mailto:francescosannicola1997@gmail.com"
                aria-label="Send Email"
              >
                <svg
                  width="18"
                  height="21"
                  fill="#000000"
                  viewBox="0 0 1920 1920"
                  xmlns="http://www.w3.org/2000/svg"
                >
                  <title>Email</title>
                  <path
                    d="M0 1694.235h1920V226H0v1468.235ZM112.941 376.664V338.94H1807.06v37.723L960 1111.233l-847.059-734.57ZM1807.06 526.198v950.513l-351.134-438.89-88.32 70.475 378.353 472.998H174.042l378.353-472.998-88.32-70.475-351.134 438.89V526.198L960 1260.768l847.059-734.57Z"
                    fill-rule="evenodd"
                  />
                </svg>
                <span class="contact-label">Email</span>
              </a>

              <a
                href="https://www.linkedin.com/in/francesco-sannicola"
                target="_blank"
                aria-label="View LinkedIn Profile"
              >
                <svg
                  fill="#000000"
                  width="18"
                  height="18"
                  viewBox="0 0 1920 1920"
                  xmlns="http://www.w3.org/2000/svg"
                >
                  <title>LinkedIn</title>
                  <path
                    d="M1168 601.321v74.955c72.312-44.925 155.796-71.11 282.643-71.11 412.852 0 465.705 308.588 465.705 577.417v733.213L1438.991 1920v-701.261c0-117.718-42.162-140.06-120.12-140.06-74.114 0-120.12 23.423-120.12 140.06V1920l-483.604-4.204V601.32H1168Zm-687.52-.792v1318.918H0V600.53h480.48Zm-120.12 120.12H120.12v1078.678h240.24V720.65Zm687.52.792H835.267v1075.316l243.364 2.162v-580.18c0-226.427 150.51-260.18 240.24-260.18 109.55 0 240.24 45.165 240.24 260.18v580.18l237.117-2.162v-614.174c0-333.334-93.573-457.298-345.585-457.298-151.472 0-217.057 44.925-281.322 98.98l-16.696 14.173H1047.88V721.441ZM240.24 0c132.493 0 240.24 107.748 240.24 240.24 0 132.493-107.747 240.24-240.24 240.24C107.748 480.48 0 372.733 0 240.24 0 107.748 107.748 0 240.24 0Zm0 120.12c-66.186 0-120.12 53.934-120.12 120.12s53.934 120.12 120.12 120.12 120.12-53.934 120.12-120.12-53.934-120.12-120.12-120.12Z"
                    fill-rule="evenodd"
                  />
                </svg>
                <span class="contact-label">LinkedIn</span>
              </a>

              <a
                href="https://github.com/francesco-s"
                target="_blank"
                aria-label="View GitHub Profile"
              >
                <svg
                  xmlns="http://www.w3.org/2000/svg"
                  x="0px"
                  y="0px"
                  width="100"
                  height="100"
                  viewBox="0 0 24 24"
                >
                  <title>GitHub</title>
                  <path
                    d="M 12 1.9921875 C 6.4855957 1.9921875 2 6.4769321 2 12 C 2 16.599161 5.1205653 20.490345 9.3671875 21.642578 A 0.50005 0.50005 0 0 0 9.9980469 21.160156 L 9.9980469 17.583984 A 0.50005 0.50005 0 0 0 9.9980469 17.398438 L 9.9980469 17 C 9.9980469 16.463435 10.20474 15.989016 10.550781 15.621094 A 0.50005 0.50005 0 0 0 10.310547 14.794922 C 8.3191985 14.288505 7 12.945349 7 11.492188 C 7 10.73278 7.3615845 9.9960348 8.015625 9.3925781 A 0.50005 0.50005 0 0 0 8.1679688 8.9277344 C 8.066665 8.41934 8.082645 7.8782734 8.0742188 7.34375 C 8.6127591 7.5825374 9.1625862 7.7923277 9.640625 8.1757812 A 0.50005 0.50005 0 0 0 10.09375 8.265625 C 10.683558 8.0925899 11.325263 7.9921875 12 7.9921875 C 12.673669 7.9921875 13.314937 8.0917915 13.904297 8.265625 A 0.50005 0.50005 0 0 0 14.359375 8.1777344 C 14.837054 7.7945694 15.386932 7.5824899 15.925781 7.34375 C 15.916981 7.8785794 15.933881 8.4199143 15.832031 8.9277344 A 0.50005 0.50005 0 0 0 15.982422 9.3945312 C 16.637666 9.9982795 17.001953 10.733923 17.001953 11.494141 C 17.001953 12.945944 15.680991 14.28753 13.689453 14.794922 A 0.50005 0.50005 0 0 0 13.449219 15.623047 C 13.794633 15.990353 14.001953 16.464434 14.001953 17 L 13.998047 21.160156 A 0.50005 0.50005 0 0 0 14.630859 21.642578 C 18.878428 20.490372 22 16.599237 22 12 C 22 6.4769321 17.514404 1.9921875 12 1.9921875 z M 12 2.9921875 C 16.973596 2.9921875 21 7.0170679 21 12 C 21 15.899732 18.470363 19.145081 14.998047 20.388672 L 15.001953 17 C 15.001953 16.421513 14.688987 15.964437 14.404297 15.505859 C 16.432596 14.813419 18.001953 13.369173 18.001953 11.494141 C 18.001953 10.506223 17.528746 9.6094427 16.826172 8.8808594 C 16.963004 8.0965535 17.032667 7.2949738 16.970703 6.4570312 A 0.50005 0.50005 0 0 0 16.3125 6.0214844 C 15.491527 6.300863 14.703446 6.7215379 13.960938 7.2734375 C 13.34208 7.110241 12.692308 6.9921875 12 6.9921875 C 11.30618 6.9921875 10.656139 7.1108109 10.037109 7.2734375 C 9.2949426 6.7217093 8.5094793 6.2989123 7.6894531 6.0195312 A 0.50005 0.50005 0 0 0 7.0292969 6.4550781 C 6.9654142 7.294134 7.0380099 8.0939393 7.1738281 8.8769531 C 6.4709034 9.6061723 6 10.504427 6 11.492188 C 6 13.367279 7.5663139 14.813867 9.59375 15.505859 C 9.3112432 15.962509 9.0029789 16.419068 9 16.992188 L 7.5 16.992188 C 7.2241522 16.992188 7.0052524 16.845238 6.7363281 16.513672 C 6.4674039 16.182105 6.2065255 15.697988 5.9277344 15.234375 A 0.50005 0.50005 0 0 0 5.46875 14.988281 A 0.50005 0.50005 0 0 0 5.0722656 15.75 C 5.3304745 16.179387 5.5979086 16.697395 5.9589844 17.142578 C 6.3200601 17.587762 6.8328478 17.992188 7.5 17.992188 L 8.9980469 17.992188 L 8.9980469 20.388672 C 5.5278881 19.144471 3 15.898951 3 12 C 3 7.0170679 7.0264043 2.9921875 12 2.9921875 z"
                  ></path>
                </svg>
                <span class="contact-label">GitHub</span>
              </a>
            </div>
          </div>
          <div class="switch">
            <input type="checkbox" id="darkModeToggle" />
            <label for="darkModeToggle" class="switch-label">
              <span class="sun-icon">&#9728;</span>
              <span class="moon-icon">&#9790;</span>
            </label>
          </div>
        </header>
      </div>
    </div>
    <div class="link-container">
      <div class="link-column">
        <a href="../"> <i class="fas fa-home"></i>Home </a>
      </div>
      <div class="link-column">
        <a href="../projects/">
          <i class="fas fa-project-diagram"></i>Projects
        </a>
      </div>
      <div class="link-column">
        <a href="../articles/"> <i class="fas fa-newspaper"></i>Articles </a>
      </div>
      <div class="link-column">
        <a href="../about.html"> <i class="fas fa-user"></i>About </a>
      </div>
    </div>
    <div class="article-container">
      <h1>
        <span style="font-size: 16px">./articles/</span> Understanding Spatial
        Indexing Trees
      </h1>
      <div class="last-updated">
        <span class="last-updated-label">Last modified:</span>
        <time datetime="2025-11-30">November 30, 2025</time>
      </div>

      <p>
        This post explores three fundamental structures, KDTrees, BallTrees, and
        the STR-packed R-tree, moving beyond scikit-learn imports to understand
        their mathematical backbones. We will dissect how they slice the
        Euclidean plane (and hyperspace), why the "Curse of Dimensionality"
        breaks some but not others.
      </p>

      <div class="summary">
        <h4>Quick Navigation</h4>
        <ol>
          <li>
            <a href="#foundations">Foundations of Spatial Partitioning</a>
          </li>
          <li><a href="#kdtree">KDTree (k-Dimensional Tree)</a></li>
          <li><a href="#balltree">BallTree (Metric Trees)</a></li>
          <li><a href="#strtree">STRtree (Sort-Tile-Recursive R-tree)</a></li>
          <li><a href="#comparison">Practical Comparison & Benchmarks</a></li>
        </ol>
      </div>

      <h2 id="foundations">1. Foundations of Spatial Partitioning</h2>
      <p>
        The starting point for all three structures (KDTree, BallTree,
        STR-packed R-tree) is the same:
        <strong>avoid scanning everything</strong>.
      </p>
      <p>
        Given a set of \(N\) geometric objects (points, line segments, polygons)
        in a domain \(X \subset \mathbb{R}^d\), the baseline way to answer a
        query is to check the query against all objects. For example:
      </p>
      <ul>
        <li>
          <strong>Range query</strong>: given a region \(R \subset
          \mathbb{R}^d\), return all objects intersecting \(R\).
          <br />
          <em>Example:</em> Find all restaurants within a 1 km radius of a
          location.
        </li>
        <li>
          <strong>k-nearest neighbor (kNN)</strong>: given a query point \(q \in
          \mathbb{R}^d\), find the \(k\) objects with minimum distance \(d(q,
          \cdot)\).
          <br />
          <em>Example:</em> Find the 5 closest ATMs to the user's current
          position.
        </li>
      </ul>
      <p>
        A naive implementation is \(O(N)\) per query. Spatial trees are
        hierarchical filters that try to achieve something closer to \(O(\log
        N)\) query time (for fixed, low dimension and "nice" distributions) by
        eliminating large chunks of space or data at once.
      </p>

      <h4>The Core Idea: Prune by Geometry, Not by IDs</h4>
      <p>
        All three structures can be viewed as trees where each node represents a
        region of space that contains some subset of the data. Very informally:
      </p>
      <ul>
        <li>
          <strong>KDTree</strong>: recursively cuts space with axis-aligned
          hyperplanes (what does it mean? Don't worry we see that in the next
          chapter).
          <figure>
            <img
              src="../assets/KDtree.png"
              alt="Visual representation of a KDTree structure with recursive axis-aligned splits"
              class="responsive-img"
              width="720"
              height="480"
            />
            <figcaption style="text-align: center">KDTree Structure</figcaption>
          </figure>
        </li>
        <li>
          <strong>BallTree</strong>: recursively groups points into nested
          metric balls (Again, we will discuss later).
          <figure>
            <img
              src="../assets/BallTree.jpg"
              alt="Visual representation of a BallTree structure with nested metric balls"
              class="responsive-img"
              width="720"
              height="480"
            />
            <figcaption style="text-align: center">
              BallTree Structure
            </figcaption>
          </figure>
        </li>
        <li>
          <strong>R-tree / STRtree</strong>: recursively groups objects into
          bounding rectangles (or boxes in higher \(d\)).
          <figure>
            <img
              src="../assets/RTree.webp"
              alt="Visual representation of an R-tree structure with hierarchical bounding rectangles"
              class="responsive-img"
              width="720"
              height="480"
            />
            <figcaption style="text-align: center">R-tree Structure</figcaption>
          </figure>
        </li>
      </ul>
      <p>
        The query algorithm then walks the tree and repeatedly answers:
        <em>"Can this entire region be safely ignored?"</em> If yes, the entire
        subtree is pruned in \(O(1)\), rather than scanning all contained
        objects.
      </p>

      <h4>Space-Partitioning vs Data-Partitioning</h4>
      <p>A useful conceptual distinction:</p>
      <p>
        <strong>Space-partitioning indexes</strong> (KDTree, quadtrees, etc.):
      </p>
      <ul>
        <li>
          Partition the geometric space \(X\) itself into disjoint regions
          (cells).
        </li>
        <li>Every point falls into exactly one region at each level.</li>
        <li>
          Nodes correspond to regions of \(X\), regardless of how many points
          are there.
        </li>
      </ul>
      <p>
        <strong>Data-partitioning indexes</strong> (R-tree, BallTree and
        variants):
      </p>
      <ul>
        <li>Partition the set of objects into groups.</li>
        <li>
          For each group, store a bounding region that encloses exactly the
          members of that group.
        </li>
        <li>
          Nodes correspond to groups of objects and their bounding shapes.
        </li>
      </ul>
      <p>This has practical consequences:</p>
      <ul>
        <li>
          In space-partitioning, you may get empty regions if space is sparsely
          populated.
        </li>
        <li>
          In data-partitioning, every node corresponds to at least one object,
          but bounding regions can overlap.
        </li>
      </ul>
      <p>Later, this will map nicely to:</p>
      <ul>
        <li>
          <strong>KDTree</strong>: clean partitions of \(\mathbb{R}^d\) with
          hyperplanes.
        </li>
        <li>
          <strong>BallTree</strong>: nested metric balls around point clusters.
        </li>
        <li>
          <strong>STRtree</strong>: packed groups of objects in minimum bounding
          rectangles (MBRs).
        </li>
      </ul>

      <h4>Formal Setup: Metric Space and Queries</h4>
      <p>Assume a metric space \((X, d)\):</p>
      <ul>
        <li>\(X\) is the set of objects (often \(X = \mathbb{R}^d\)).</li>
        <li>
          \(d: X \times X \to \mathbb{R}_{\geq 0}\) is a metric satisfying:
        </li>
      </ul>
      <ul>
        <li>
          <strong>Non-negativity and identity</strong>: \(d(x, y) \geq 0\),
          \(d(x, y) = 0 \Leftrightarrow x = y\).
        </li>
        <li><strong>Symmetry</strong>: \(d(x, y) = d(y, x)\).</li>
        <li>
          <strong>Triangle inequality</strong>: \(d(x, z) \leq d(x, y) + d(y,
          z)\).
        </li>
      </ul>
      <p>Common queries:</p>
      <ul>
        <li>
          <strong>Range query</strong> with radius \(r\) around \(q\):
          <p class="responsive-math">
            \[ B(q, r) = \{x \in X \mid d(x, q) \leq r\} \]
          </p>
        </li>
        <li>
          <strong>kNN query</strong>:
          <p class="responsive-math">
            \[ \text{kNN}(q, k) = \{x_1, \ldots, x_k \in X \mid d(q, x_i) \text{
            are the } k \text{ smallest distances}\} \]
          </p>
        </li>
      </ul>
      <p>Naive evaluation has:</p>
      <ul>
        <li>
          <strong>Time complexity</strong>: \(\Theta(N \cdot C_d)\), where
          \(C_d\) is the cost of computing distance in dimension \(d\).
        </li>
        <li>
          <strong>Space complexity</strong>: \(\Theta(N)\) for the raw data plus
          no additional indexing structure.
        </li>
      </ul>
      <p>
        Hierarchical structures aim to reduce average-case query time to roughly
        \(O(\log N)\) for moderate \(d\), at the price of extra memory and build
        time.
      </p>

      <h4>Concrete Example: Range Query in 2D</h4>
      <p>Consider \(N = 10^6\) 2D points (e.g. GPS coordinates):</p>
      <p>Why \(10^6\)? It's a realistic scale for modern spatial queries:</p>
      <ul>
        <li>A single city (e.g., Manhattan) has ~1M addresses/POIs.</li>
        <li>
          A smartphone map application must handle ~1M tiles or features in
          viewport range.
        </li>
        <li>
          Naive \(O(N)\) scanning of 1M points takes ~100 ms; indexed \(O(\log
          N)\) takes ~1 ms—a 100× speedup.
        </li>
      </ul>

      <p class="responsive-math">
        \[ P = \{p_1, \ldots, p_N\} \subset \mathbb{R}^2 \]
      </p>
      <p>Suppose we want all points inside the axis-aligned rectangle:</p>
      <p class="responsive-math">
        \[ R = [x_{\min}, x_{\max}] \times [y_{\min}, y_{\max}] \]
      </p>

      <p><strong>Naive Scan:</strong></p>
      <p>For each point \(p_i = (x_i, y_i)\), check:</p>
      <p class="responsive-math">
        \[ x_{\min} \leq x_i \leq x_{\max} \quad \text{and} \quad y_{\min} \leq
        y_i \leq y_{\max} \]
      </p>
      <p>
        This is 2 comparisons per coordinate, \(O(N)\) test cost, and must be
        repeated for every query.
      </p>

      <h4>Example: KDTree Perspective</h4>
      <p>A KDTree on these points does the following:</p>
      <ol>
        <li>
          At the root, choose a split dimension (e.g. \(x\)) and a split value
          \(s\) (usually median of x-coordinates):
          <ul>
            <li>Left subtree: all points with \(x \leq s\).</li>
            <li>Right subtree: all points with \(x > s\).</li>
          </ul>
        </li>
        <li>
          At the next level, alternate dimension (e.g. \(y\)), and split each
          side again by median \(y\).
        </li>
      </ol>
      <p>Geometrically, space is recursively cut by axis-aligned lines:</p>
      <ul>
        <li>Level 0: vertical line \(x = s_0\).</li>
        <li>
          Level 1: horizontal lines \(y = s_{1,\text{left}}\), \(y =
          s_{1,\text{right}}\).
        </li>
        <li>Level 2: another set of vertical cuts, etc.</li>
      </ul>
      <p>
        After building, each node represents a hyperrectangle (here, a 2D
        rectangle) where all its points lie. For a range query rectangle \(R\):
      </p>
      <ul>
        <li>At each node, you know the node's bounding rectangle \(B\).</li>
        <li>
          If \(B \cap R = \emptyset\), then no point in that subtree can be in
          \(R\): prune.
        </li>
        <li>
          If \(B \subseteq R\), then all points in that subtree are in \(R\):
          accept entire subtree without checking individual points.
        </li>
        <li>Otherwise, recurse to children.</li>
      </ul>
      <p>
        If the KDTree is balanced and data is well-distributed, you can rule out
        most of the space quickly, leading to much less than \(N\) point checks
        on average.
      </p>

      <h4>Example: R-tree / STRtree Perspective</h4>
      <p>
        Now suppose the data are not points but rectangles: e.g., building
        footprints in a city. Let each object be an axis-aligned bounding box:
      </p>
      <p class="responsive-math">
        \[ o_i = [x_{i,\min}, x_{i,\max}] \times [y_{i,\min}, y_{i,\max}] \]
      </p>
      <p>
        An R-tree (and STRtree as a specific packed variant) groups objects into
        nodes, and for each node stores a Minimum Bounding Rectangle (MBR) that
        covers all its children:
      </p>
      <p class="responsive-math">
        \[ \text{MBR}(\mathcal{N}) = \left[\min_i x_{i,\min}, \max_i
        x_{i,\max}\right] \times \left[\min_i y_{i,\min}, \max_i
        y_{i,\max}\right] \]
      </p>
      <p>For a range query with rectangle \(R\):</p>
      <ul>
        <li>At each node with MBR \(B\):</li>
        <li>If \(B \cap R = \emptyset\): prune this subtree.</li>
        <li>
          If \(B \cap R \neq \emptyset\): descend; at leaves, test query
          rectangle \(R\) against each stored object.
        </li>
      </ul>
      <p>
        STRtree in particular tries to pack rectangles such that sibling MBRs
        overlap as little as possible and are filled close to capacity,
        optimizing for static datasets.
      </p>

      <h4>Example: BallTree Perspective</h4>
      <p>
        For high-dimensional vectors, axis-aligned splits (KDTree) may be less
        effective because distances start to "look similar" in all directions
        (one manifestation of the curse of dimensionality). BallTrees do not
        rely on coordinate axes:
      </p>
      <p>
        Each node stores a center \(c \in \mathbb{R}^d\) and a radius \(r\) such
        that every point in that node satisfies:
      </p>
      <p class="responsive-math">
        \[ \forall x \text{ in the node: } d(x, c) \leq r \]
      </p>
      <p>
        Here, \(x\) denotes any data point contained in the node's subtree
        (i.e., an element of the indexed point set).
      </p>
      <p>
        Children are sub-balls that partition the set of points, often by some
        heuristic (e.g., splitting along direction of greatest spread).
      </p>
      <p>For a kNN query with point \(q\):</p>
      <ul>
        <li>At node \((c, r)\), use the triangle inequality:</li>
      </ul>
      <p class="responsive-math">
        \[ \forall x \text{ in node}, \quad d(q, x) \geq d(q, c) - d(x, c) \geq
        d(q, c) - r \]
      </p>
      <p>
        This inequality states that any point \(x\) inside the ball is at least
        \(d(q, c) - r\) away from the query point \(q\). Since all points in the
        ball satisfy \(d(x, c) \leq r\), the minimum possible distance from
        \(q\) to any point in the ball is \(d(q, c) - r\).
      </p>
      <ul>
        <li>
          If the current best k-th nearest distance is \(D_k\), and \(d(q, c) -
          r > D_k\), then the entire ball cannot contain a closer neighbor than
          the current best: prune the node.
        </li>
        <li>
          In range queries, if \(d(q, c) - r > R\) for a search radius \(R\),
          the node can be discarded entirely.
        </li>
      </ul>
      <p>
        Note how BallTrees work purely with distances and the triangle
        inequality, making them more flexible than KDTree and R-tree in
        arbitrary metrics (e.g., cosine distance, Haversine distance).
      </p>

      <h4>Complexity Intuition and the Curse of Dimensionality</h4>
      <p>
        In low-dimensional Euclidean space (\(d\) small and fixed), spatial
        trees often achieve:
      </p>
      <ul>
        <li>Build time around \(O(N \log N)\).</li>
        <li>
          Average query time around \(O(\log N)\) for balanced trees and
          well-behaved data distributions.
        </li>
      </ul>
      <p>However, as dimension \(d\) grows:</p>
      <ul>
        <li>
          The volume of the unit ball in \(\mathbb{R}^d\) shrinks compared to
          the hypercube.
          <br />
          <em>Example:</em> In 1D, a ball of radius 1 occupies the interval
          \([-1, 1]\) (length 2) within the cube \([-1, 1]\) (length 2): 100%
          coverage. In 10D, the unit ball occupies only ~2.5% of the unit
          hypercube, leaving vast empty corners.
        </li>
        <li>
          Distances between random points tend to concentrate around a narrow
          band (distance concentration phenomenon).
          <br />
          <em>Example:</em> In 100D Euclidean space, if you sample 1000 random
          points uniformly in \([0,1]^{100}\), pairwise distances cluster
          tightly around ~\(\sqrt{50}\) (the median), with little variation. A
          "nearest neighbor" is almost as far as an arbitrary point, making
          pruning ineffective.
        </li>
        <li>
          Any bounding shape that must contain a "local neighborhood" of points
          tends to encompass a large portion of space, so pruning becomes
          ineffective.
          <br />
          <em>Example:</em> In 50D, to enclose the 10 nearest neighbors of a
          query point, a hyperrectangle may need to expand to cover 30% of the
          total data space, forcing the algorithm to examine thousands of
          irrelevant points instead of pruning.
        </li>
      </ul>
      <p>
        Formally, the "curse of dimensionality" refers to these phenomena where
        the complexity of search grows exponentially with dimension, making many
        spatial indexes no better than a linear scan for high \(d\). In
        practice, KDTree and BallTree are mainly effective for moderate
        dimensions and specific distributions; for embedding spaces with \(d
        \sim 100\text{–}1000\), approximate methods or different structures
        (LSH, graph-based ANN, etc.) are typically used.
      </p>

      <h4>Takeaways</h4>
      <p>Of this introduction you can forget everything, but:</p>
      <ul>
        <li>
          <strong
            >Spatial trees exploit geometry to prune large parts of the dataset
            for each query.</strong
          >
          The fundamental motivation is replacing \(O(N)\) scans with
          logarithmic-time queries by eliminating irrelevant regions in one
          step.
        </li>
        <li>
          <strong
            >There is a clear conceptual split between space-partitioning
            (KDTree) and data-partitioning (BallTree, R-tree).</strong
          >
          <ul>
            <li>
              Space-partitioning: recursively divide the geometric domain itself
              into disjoint cells.
            </li>
            <li>
              Data-partitioning: recursively group objects and store bounding
              envelopes (whose regions may overlap).
            </li>
          </ul>
        </li>
        <li>
          <strong>All rely on three key ingredients:</strong>
          <ul>
            <li>
              <strong>Bounding regions</strong>: axis-aligned rectangles
              (R-tree), metric balls (BallTree, the name helps a lot), or
              axis-aligned hyperrectangles (KDTree).
            </li>
            <li>
              <strong>Metrics and triangle inequality</strong>: the triangle
              inequality \(d(x, z) \leq d(x, y) + d(y, z)\) is the mathematical
              hammer that allows pruning based on distance bounds without
              explicit object inspection.
            </li>
            <li>
              <strong>Hierarchical decomposition</strong>: recursive
              partitioning creates a tree where depth is logarithmic in dataset
              size, enabling efficient top-down filtering.
            </li>
          </ul>
        </li>
        <li>
          <strong>Their effectiveness is strongly dimension-dependent</strong>
          due to the curse of dimensionality. As \(d\) grows, bounding regions
          enlarge relative to "useful" space, and pruning power diminishes.
          These structures remain effective in low-to-moderate dimensions; for
          very high-dimensional data, approximate or graph-based methods are
          preferred.
        </li>
      </ul>

      <h2 id="kdtree">2. KDTree: The Space-Partitioning Baseline</h2>
      <p>
        The k-dimensional tree (KDTree) is the conceptually simplest of the
        three structures: it recursively bisects k-dimensional space using
        axis-aligned hyperplanes. Unlike the data-partitioning approaches that
        group objects and store bounding envelopes, a KDTree partitions space
        itself into nested rectangular cells. This clean geometric
        interpretation makes it an ideal starting point for understanding
        spatial hierarchies.
      </p>

      <h4>Core Concept: Binary Space Partitioning</h4>
      <p>A KDTree is a binary tree where each node stores:</p>
      <ul>
        <li>A point \(p = (p_1, p_2, \ldots, p_k) \in \mathbb{R}^k\).</li>
        <li>
          A split dimension \(d \in \{0, 1, \ldots, k-1\}\) (cycling through
          coordinates).
        </li>
        <li>
          Left and right subtrees, containing points to the left and right of
          the splitting hyperplane respectively.
        </li>
      </ul>
      <p>
        The splitting hyperplane is defined implicitly: it passes through the
        point \(p\) and is perpendicular to dimension \(d\). A point \(q = (q_1,
        \ldots, q_k)\) goes left if \(q_d < p_d\) and right if \(q_d \geq p_d\).
      </p>
      <p>
        <strong>Key Geometric Invariant:</strong> Each node in the KDTree
        corresponds to an axis-aligned hyperrectangle (a box in k-dimensional
        space). All points in the node's left subtree lie strictly to the left
        of the hyperplane; all in the right subtree lie strictly to the right.
        This partitioning is complete and disjoint: every point in the dataset
        falls into exactly one rectangular cell at each tree level.
      </p>

      <h4>Concrete Example: 2D Points</h4>
      <p>Consider four points in \(\mathbb{R}^2\):</p>
      <p class="responsive-math">\[ P = \{(2,5), (6,3), (3,8), (8,9)\} \]</p>
      <p>A typical KDTree construction proceeds as follows:</p>
      <ol>
        <li>
          <strong>At the root:</strong> Split by the x-axis. The median
          x-coordinate is between 3 and 6; we select pivot point \((6,3)\).
          <ul>
            <li>Left subtree: \((2,5), (3,8)\) (both have \(x < 6\)).</li>
            <li>Right subtree: \((8,9)\) (has \(x > 6\)).</li>
          </ul>
        </li>
        <li>
          <strong>At the left child:</strong> Split by the y-axis. Points
          \((2,5)\) and \((3,8)\) differ in y; median y is between them, so
          pivot is \((3,8)\).
          <ul>
            <li>Left-left: \((2,5)\) (has \(y < 8\)).</li>
            <li>Left-right: empty.</li>
          </ul>
        </li>
        <li>
          <strong>At the right child:</strong> Only one point \((8,9)\); it
          becomes a leaf.
        </li>
      </ol>
      <p>The resulting tree has the structure:</p>
      <svg
        width="600"
        height="400"
        viewBox="0 0 600 400"
        xmlns="http://www.w3.org/2000/svg"
      >
        <!-- Define styles -->
        <defs>
          <style>
            .node-circle {
              fill: #e8f5e9;
              stroke: #388e3c;
              stroke-width: 2;
            }
            .connection {
              stroke: #666;
              stroke-width: 2;
              fill: none;
            }
            .node-text {
              font-family: Arial, sans-serif;
              font-size: 14px;
              fill: #333;
              font-weight: bold;
            }
            .split-text {
              font-family: monospace;
              font-size: 12px;
              fill: #d32f2f;
            }
          </style>
        </defs>

        <!-- Connections -->
        <path class="connection" d="M 300 80 L 150 180" />
        <path class="connection" d="M 300 80 L 450 180" />
        <path class="connection" d="M 150 180 L 80 300" />
        <path
          class="connection"
          d="M 150 180 L 220 300"
          stroke-dasharray="4,4"
        />

        <!-- Root Node -->
        <circle class="node-circle" cx="300" cy="80" r="45" />
        <text class="node-text" x="300" y="85" text-anchor="middle">
          (6, 3)
        </text>
        <text class="split-text" x="300" y="105" text-anchor="middle">
          [split on x=6]
        </text>

        <!-- Left Child Node -->
        <circle class="node-circle" cx="150" cy="180" r="45" />
        <text class="node-text" x="150" y="185" text-anchor="middle">
          (3, 8)
        </text>
        <text class="split-text" x="150" y="205" text-anchor="middle">
          [y=8]
        </text>

        <!-- Right Child Node -->
        <circle class="node-circle" cx="450" cy="180" r="45" />
        <text class="node-text" x="450" y="190" text-anchor="middle">
          (8, 9)
        </text>

        <!-- Left-Left Leaf Node -->
        <circle class="node-circle" cx="80" cy="300" r="45" />
        <text class="node-text" x="80" y="310" text-anchor="middle">
          (2, 5)
        </text>

        <!-- Right Empty Node -->
        <circle class="node-circle" cx="220" cy="300" r="45" fill="#f5f5f5" />
        <text
          class="node-text"
          x="220"
          y="315"
          text-anchor="middle"
          font-size="24"
        >
          ø
        </text>
      </svg>
      <p>
        The hyperplanes recursively partition the 2D plane. Points \((2,5)\) and
        \((3,8)\) lie in the region \(\{(x,y): x < 6, y < 8\}\) and \(\{(x,y): x
        < 6, y \geq 8\}\), respectively, while \((8,9)\) lies in \(\{(x,y): x
        \geq 6\}\).
      </p>

      <h4>Construction: The Median-Based Approach</h4>
      <p>The standard algorithm for building a balanced KDTree is:</p>
      <p><strong>Algorithm: Construct KDTree</strong></p>
      <ol>
        <li>If the point set is empty, return an empty tree.</li>
        <li>
          Select a pivot point and split dimension using a pivot-choosing
          heuristic.
        </li>
        <li>Remove the pivot from the set.</li>
        <li>
          Partition remaining points:
          <ul>
            <li>
              Left partition: all \(d'\) with coordinate \(d\) less than pivot's
              coordinate \(d\).
            </li>
            <li>
              Right partition: all \(d'\) with coordinate \(d\) greater than or
              equal to pivot's coordinate \(d\).
            </li>
          </ul>
        </li>
        <li>Recursively build left and right subtrees from the partitions.</li>
        <li>
          Return a node containing the pivot, split dimension, and two subtrees.
        </li>
      </ol>
      <p>
        <strong>Complexity:</strong> \(O(N \log N)\) build time, assuming a
        balanced tree where median selection takes \(O(N)\) and each recursive
        call halves the dataset.
      </p>

      <h4>Pivot Selection Strategy</h4>
      <p>
        The choice of pivot affects tree balance and search efficiency. The
        standard approach is:
      </p>
      <ul>
        <li>
          Select the splitting dimension as the coordinate with the largest
          variance (widest spread) in the current point set.
        </li>
        <li>Choose the pivot as the median point along that dimension.</li>
      </ul>
      <p>
        This heuristic tends to produce relatively square hyperrectangles and
        maintains tree balance. However, for skewed distributions, it can
        produce long, thin cells that reduce pruning opportunities in
        nearest-neighbor search.
      </p>

      <h4>Nearest-Neighbor Search: The Core Query</h4>
      <p>
        Given a query point \(q\) and the KDTree, the goal is to find the point
        in the tree closest to \(q\) under Euclidean distance:
      </p>
      <p class="responsive-math">\[ \arg\min_{p \in P} \|q - p\|_2 \]</p>

      <p><strong>Algorithm Outline</strong></p>
      <p>The search proceeds in two phases:</p>
      <p><strong>Phase 1: Locate an initial candidate</strong></p>
      <p>
        Descend the tree greedily, always following the branch containing \(q\):
      </p>
      <ul>
        <li>
          At each node with split dimension \(d\): if \(q_d < p_d\), go left;
          otherwise, go right.
        </li>
        <li>
          Reach a leaf node and record its point as the best candidate so far.
          Let \(D_{\text{best}}\) be the squared distance from \(q\) to this
          point (we avoid square roots for efficiency).
        </li>
      </ul>

      <p><strong>Phase 2: Backtrack and prune</strong></p>
      <p>Return up the tree, and at each node, perform two checks:</p>
      <ul>
        <li>
          <strong>Update check:</strong> Compute the distance from \(q\) to the
          current node's point. If closer than \(D_{\text{best}}\), update the
          best.
        </li>
        <li>
          <strong>Pruning check:</strong> Determine whether the "other child"
          (the subtree not containing \(q\)) could possibly contain a closer
          point.
        </li>
      </ul>
      <p>
        The key insight is the
        <strong>axis-aligned distance-to-hyperplane test</strong>: at a node
        splitting on dimension \(s\), the distance from \(q\) to the splitting
        hyperplane is simply:
      </p>
      <p class="responsive-math">\[ d_{\text{plane}} = |q_s - p_s| \]</p>
      <p>
        where \(p_s\) is the split point's s-th coordinate. If
        \(d_{\text{plane}}^2 > D_{\text{best}}\), then the entire "other"
        subtree's hyperrectangle is too far away; prune it.
      </p>
      <p>
        If \(d_{\text{plane}}^2 \leq D_{\text{best}}\), the other subtree may
        contain closer points; recursively search it.
      </p>

      <h4>Computing the Distance-to-Hyperplane</h4>
      <p>
        The hyperplane at a node is perpendicular to dimension \(s\) and passes
        through the split point's coordinate. The distance from query point
        \(q\) to this plane (in the s-dimension) is:
      </p>
      <p class="responsive-math">\[ d_{\text{plane}}^2 = (q_s - p_s)^2 \]</p>
      <p>
        This is compared directly against the squared distance to the current
        best: if \(d_{\text{plane}}^2 > D_{\text{best}}\), the other side is
        guaranteed to have no closer points (because any point there must be at
        least \(d_{\text{plane}}\) away in the s-dimension alone).
      </p>

      <h4>Concrete 2D Example</h4>
      <p>Build the tree using points \(P = \{(2,5), (6,3), (3,8), (8,9)\}\):</p>
      <p><strong>Tree Structure:</strong></p>
      <svg
        width="600"
        height="400"
        viewBox="0 0 600 400"
        xmlns="http://www.w3.org/2000/svg"
      >
        <!-- Define styles -->
        <defs>
          <style>
            .node-circle {
              fill: #e8f5e9;
              stroke: #388e3c;
              stroke-width: 2;
            }
            .connection {
              stroke: #666;
              stroke-width: 2;
              fill: none;
            }
            .node-text {
              font-family: Arial, sans-serif;
              font-size: 14px;
              fill: #333;
              font-weight: bold;
            }
            .split-text {
              font-family: monospace;
              font-size: 12px;
              fill: #d32f2f;
            }
          </style>
        </defs>

        <!-- Connections -->
        <path class="connection" d="M 300 80 L 150 180" />
        <path class="connection" d="M 300 80 L 450 180" />
        <path class="connection" d="M 150 180 L 80 300" />

        <!-- Root Node -->
        <circle class="node-circle" cx="300" cy="80" r="45" />
        <text class="node-text" x="300" y="85" text-anchor="middle">
          (6, 3)
        </text>
        <text class="split-text" x="300" y="105" text-anchor="middle">
          [split on x=6]
        </text>

        <!-- Left Child Node -->
        <circle class="node-circle" cx="150" cy="180" r="45" />
        <text class="node-text" x="150" y="185" text-anchor="middle">
          (3, 8)
        </text>
        <text class="split-text" x="150" y="205" text-anchor="middle">
          [y=8]
        </text>

        <!-- Right Child Node -->
        <circle class="node-circle" cx="450" cy="180" r="45" />
        <text class="node-text" x="450" y="190" text-anchor="middle">
          (8, 9)
        </text>

        <!-- Left-Left Leaf Node -->
        <circle class="node-circle" cx="80" cy="300" r="45" />
        <text class="node-text" x="80" y="310" text-anchor="middle">
          (2, 5)
        </text>
      </svg>
      <p>Now query for the nearest neighbor to \(q = (5,6)\):</p>

      <p><strong>Step 1: Descent</strong></p>
      <ul>
        <li>
          At root \((6,3)\), split dimension is \(x = 6\). Is \(5 < 6\)? Yes →
          go left.
        </li>
        <li>
          At node \((3,8)\), split dimension is \(y = 8\). Is \(6 < 8\)? Yes →
          go left.
        </li>
        <li>Reach leaf \((2,5)\).</li>
      </ul>

      <p><strong>Step 2: Initialize best</strong></p>
      <p>Distance from \(q = (5,6)\) to \((2,5)\):</p>
      <p class="responsive-math">
        \[ D_{\text{best}}^2 = (5-2)^2 + (6-5)^2 = 9 + 1 = 10 \]
      </p>

      <p><strong>Step 3: Backtrack to node (3,8)</strong></p>
      <p>Check the point \((3,8)\) itself:</p>
      <p class="responsive-math">
        \[ d((5,6), (3,8)) = (5-3)^2 + (6-8)^2 = 4 + 4 = 8 \]
      </p>
      <p>Since \(8 < 10\), update: \(D_{\text{best}}^2 = 8\).</p>
      <p>
        Pruning check at \((3,8)\): split dimension is \(y = 8\). The "other"
        child (right, for \(y \geq 8\)) has distance to splitting plane:
      </p>
      <p class="responsive-math">\[ d_{\text{plane}}^2 = (6-8)^2 = 4 \]</p>
      <p>
        Is \(4 \leq 8\)? Yes → the other child might contain closer points. But
        \((3,8)\) has no right child, so nothing to explore.
      </p>

      <p><strong>Step 4: Backtrack to root (6,3)</strong></p>
      <p>Check the point \((6,3)\) itself:</p>
      <p class="responsive-math">
        \[ d((5,6), (6,3)) = (5-6)^2 + (6-3)^2 = 1 + 9 = 10 \]
      </p>
      <p>Since \(10 \not< 8\), do not update.</p>
      <p>
        Pruning check at \((6,3)\): split dimension is \(x = 6\). The "other"
        child (right, for \(x \geq 6\)) has distance to splitting plane:
      </p>
      <p class="responsive-math">\[ d_{\text{plane}}^2 = (5-6)^2 = 1 \]</p>
      <p>
        Is \(1 \leq 8\)? Yes → the other child might contain closer points.
        Recursively search it.
      </p>

      <p><strong>Step 5: Search right subtree (containing (8,9))</strong></p>
      <p>At node \((8,9)\), check the point itself:</p>
      <p class="responsive-math">
        \[ d((5,6), (8,9)) = (5-8)^2 + (6-9)^2 = 9 + 9 = 18 \]
      </p>
      <p>Since \(18 \not< 8\), do not update. \((8,9)\) is a leaf, so done.</p>

      <p><strong>Step 6: Result</strong></p>
      <p>The nearest neighbor is \((3,8)\) with squared distance 8.</p>

      <h4>Complexity Analysis</h4>
      <p><strong>Time Complexity</strong></p>
      <ul>
        <li>
          <strong>Construction:</strong> \(O(N \log N)\) for a balanced tree, as
          median selection and partitioning each take \(O(N)\) per level, and
          there are \(O(\log N)\) levels.
        </li>
        <li>
          <strong>Nearest-neighbor query:</strong>
          <ul>
            <li>
              <em>Best case:</em> \(O(\log N)\) if the query point is surrounded
              by data points and only one branch needs to be explored (no
              backtracking).
            </li>
            <li>
              <em>Average case</em> (well-distributed data, low dimension):
              Asymptotically \(O(\log N)\) in the number of tree levels
              descended, plus \(O(c_d)\) node examinations due to backtracking,
              where \(c_d\) depends on dimension and is independent of \(N\) for
              fixed low \(d\).
            </li>
            <li>
              <em>Worst case:</em> \(O(N)\) if the data forms pathological
              configurations. For instance, if all points lie on a circle around
              \(q\), the search radius encompasses many hyperrectangles, forcing
              examination of many leaves.
            </li>
          </ul>
        </li>
        <li>
          <strong>Range query</strong> (all points within radius \(r\) of
          \(q\)): \(O(\log N + K)\), where \(K\) is the number of reported
          points. The logarithmic term accounts for tree traversal; the linear
          term counts output points.
        </li>
      </ul>
      <p><strong>Space Complexity</strong></p>
      <p>
        \(O(N)\) to store all points, plus \(O(N)\) internal nodes, for a total
        of \(\Theta(N)\).
      </p>

      <h4>The Curse of Dimensionality in KDTree</h4>
      <p>
        While KDTrees work well in low-dimensional spaces (\(d \leq 10\) or so
        for typical data), their performance degrades sharply as dimension
        increases. Moore's empirical study provides crucial insights:
      </p>
      <ul>
        <li>
          <strong>Search nodes vs. tree size:</strong> After initial scaling,
          the number of nodes inspected is essentially independent of \(N\)
          (roughly logarithmic descent to a leaf, plus constant backtracking).
          This agrees with theory for well-behaved data.
        </li>
        <li>
          <strong>Search nodes vs. dimension \(k_{\text{dom}}\):</strong> The
          number of inspected nodes rises exponentially or quasi-exponentially
          with the full dimension of the domain vectors. For example, in a
          14-dimensional tree, increasing from 1D to 13D increases node
          inspections from roughly 1 to 400+.
        </li>
        <li>
          <strong
            >Search nodes vs. intrinsic dimensionality
            \(d_{\text{intrinsic}}\):</strong
          >
          The critical factor is not the embedding dimension \(k_{\text{dom}}\)
          but the intrinsic dimensionality of the data distribution (e.g., if
          1000D vectors all lie on a 3D manifold, performance depends on 3, not
          1000). When intrinsic dimension is fixed and embedding dimension
          varies, search costs scale only linearly.
        </li>
      </ul>
      <p>
        <strong>Intuition:</strong> As dimension grows, the volume of the unit
        hypersphere shrinks relative to the unit hypercube. Distances between
        random points concentrate around a narrow band, so a sphere of "fixed
        radius" contains an increasing fraction of all points. Consequently,
        hyperrectangle-based pruning becomes ineffective, and the tree devolves
        toward linear scan.
      </p>

      <h4>KDTree: Strengths and Limitations</h4>
      <p><strong>Strengths</strong></p>
      <ul>
        <li>
          <strong>Conceptual clarity:</strong> Axis-aligned splits are
          geometrically transparent and easy to visualize.
        </li>
        <li>
          <strong>Efficient in low dimensions:</strong> For \(d \lesssim 10\)
          and well-distributed data, queries are fast.
        </li>
        <li>
          <strong>Simple implementation:</strong> Recursive structure is
          straightforward to code.
        </li>
        <li>
          <strong>Balanced tree guarantees:</strong> Median-based construction
          ensures \(O(\log N)\) tree depth.
        </li>
      </ul>
      <p><strong>Limitations</strong></p>
      <ul>
        <li>
          <strong>Curse of dimensionality:</strong> Search performance collapses
          in high-dimensional spaces. Even with intrinsic structure, performance
          depends critically on whether query points come from the same
          distribution as indexed data.
        </li>
        <li>
          <strong>Space partitioning overhead:</strong> Axis-aligned splits can
          create many empty cells in sparse regions, wasting memory.
        </li>
        <li>
          <strong>Axis-aligned bias:</strong> For data with anisotropic
          structure not aligned to coordinate axes, splits are suboptimal.
        </li>
        <li>
          <strong>Static optimality:</strong> Once built with a fixed pivot
          strategy, the tree cannot adapt to query patterns.
        </li>
      </ul>

      <h4>Takeaway</h4>
      <p>
        The KDTree represents the geometric ideal of spatial partitioning:
        clean, recursive, easy to understand. Its nearest-neighbor search
        algorithm introduces the core concept of backtracking pruning, which
        extends to more complex structures like BallTrees and R-trees.
      </p>
      <p>
        However, its vulnerability to dimensionality motivates the next
        structures: BallTrees relax the axis-aligned constraint in favor of
        metric-based pruning (the triangle inequality), while R-trees abandon
        space partitioning entirely in favor of grouping objects by bounding
        envelopes.
      </p>
      <h2 id="balltree">3. BallTree: The Metric Tree Alternative</h2>
      <p>
        The BallTree (or metric tree) is a space-partitioning data structure
        that recursively partitions data into nested hyperspheres (balls). By
        moving away from rigid axis-aligned boundaries to metric-based
        partitioning, BallTrees become robust in high dimensions and adaptable
        to arbitrary distance functions beyond simple Euclidean geometry.
      </p>

      <h4>Core Concept: Partitioning by Hyperspheres</h4>
      <p>
        A BallTree is a binary tree where each node defines a \(D\)-dimensional
        ball characterized by:
      </p>
      <ul>
        <li>
          A center \(c \in \mathbb{R}^D\) (typically a data point or computed
          centroid).
        </li>
        <li>
          A radius \(r \ge 0\) such that every point \(p\) in the node's subtree
          satisfies: \(d(p, c) \le r\).
        </li>
      </ul>
      <p>
        The ball is the minimum enclosing sphere of all points in that subtree.
        Because balls are defined solely by distance (radius) from a center,
        they can "rotate" arbitrarily to adapt to the data's intrinsic geometry,
        regardless of the coordinate axes.
      </p>

      <h4>Key Metric Property</h4>
      <p>
        For any query point \(q\) outside a ball \((c, r)\), the distance to any
        point inside the ball satisfies:
      </p>
      <p class="responsive-math">
        \[ \forall p \in \text{ball}(c, r): \quad d(q, p) \ge \max(0, d(q, c) -
        r) \]
      </p>
      <p>
        This lower bound follows directly from the triangle inequality and is
        the core pruning mechanism. It provides a mathematically rigorous
        guarantee that no point in the pruned subtree can be closer than the
        lower bound, enabling safe search space elimination.
      </p>

      <h4>Construction: The Farthest-Point Strategy</h4>
      <p>
        The standard construction algorithm uses a "farthest-point" heuristic to
        split data. This method focuses on distinguishing clusters rather than
        strictly balancing the tree structure.
      </p>
      <p><strong>Algorithm: Construct BallTree Node</strong></p>
      <ol>
        <li>
          <strong>Compute Centroid:</strong> \(\mu = \frac{1}{|X|}\sum_{x \in X}
          x\).
        </li>
        <li>
          <strong>Pivot 1:</strong> Find point \(p_1 \in X\) farthest from
          \(\mu\).
        </li>
        <li>
          <strong>Pivot 2:</strong> Find point \(p_2 \in X\) farthest from
          \(p_1\).
        </li>
        <li>
          <strong>Partition:</strong> Assign every point to the closer pivot
          (forming \(X_L\) for points closer to \(p_1\) and \(X_R\) for points
          closer to \(p_2\)).
        </li>
        <li>
          <strong>Bound:</strong> Compute the smallest radius \(r_L, r_R\) for
          each child group that encloses all its assigned points.
        </li>
        <li>
          <strong>Recurse:</strong> Repeat for children until leaf size
          (typically 30–50 points) is reached.
        </li>
      </ol>
      <p>
        <strong>Rationale:</strong> The pair of farthest points tends to
        separate dense clusters from outliers, which improves pruning efficiency
        during search. However, this strategy does not guarantee balanced
        partitions; clusters of varying density can lead to variable tree depth.
      </p>
      <p>
        <strong>Construction Complexity:</strong> \(O(N \log N)\) average case,
        though with a higher constant factor than simpler methods due to the
        cost of distance calculations at every level.
      </p>

      <h4>Concrete Example: The "Messiness" of Metric Clustering</h4>
      <p>
        Let's trace this on our four points: \(P = \{(2,5), (6,3), (3,8),
        (8,9)\}\).
      </p>
      <p><strong>Step 1: Root Node</strong></p>
      <ul>
        <li>Centroid: \(\mu \approx (4.75, 6.25)\).</li>
        <li>Farthest from \(\mu\): \((8, 9)\) at distance \(\approx 4.26\).</li>
        <li>Pivot 1: \(p_1 = (8, 9)\).</li>
        <li>
          Pivot 2 (farthest from \(p_1\)): \((2, 5)\) at distance \(\approx
          7.2\).
        </li>
        <li>
          <strong>Partition:</strong>
          <ul>
            <li>\((8, 9) \to\) closer to \(p_1\) (distance 0).</li>
            <li>\((2, 5), (3, 8), (6, 3) \to\) all closer to \(p_2\).</li>
          </ul>
        </li>
      </ul>
      <p>
        <strong>Result:</strong> Highly unbalanced split. <br />Right Child:
        \(\{(8, 9)\}\) (Leaf). <br />Left Child: \(\{(2, 5), (3, 8), (6, 3)\}\)
        (requires further splitting).
      </p>

      <p><strong>Step 2: Left Child Processing</strong></p>
      <p>
        Process \(\{(2, 5), (3, 8), (6, 3)\}\). Centroid \(\approx (3.67,
        5.33)\).
      </p>
      <ul>
        <li>Pivot 1: \((6, 3)\). Pivot 2: \((3, 8)\).</li>
        <li>
          <strong>Partition:</strong>
          <ul>
            <li>\((6, 3) \to\) Left Child (closer to \(p_1\)).</li>
            <li>\((3, 8), (2, 5) \to\) Right Child (closer to \(p_2\)).</li>
          </ul>
        </li>
      </ul>
      <p>Resulting Tree Structure:</p>
      <svg
        width="600"
        height="400"
        viewBox="0 0 600 400"
        xmlns="http://www.w3.org/2000/svg"
      >
        <!-- Define styles -->
        <defs>
          <style>
            .node-circle {
              fill: #e3f2fd;
              stroke: #1976d2;
              stroke-width: 2;
            }
            .leaf-circle {
              fill: #fff3e0;
              stroke: #f57c00;
              stroke-width: 2;
            }
            .connection {
              stroke: #666;
              stroke-width: 2;
              fill: none;
            }
            .node-text {
              font-family: Arial, sans-serif;
              font-size: 12px;
              fill: #333;
            }
            .label-text {
              font-family: Arial, sans-serif;
              font-size: 11px;
              fill: #666;
            }
            .point-text {
              font-family: monospace;
              font-size: 10px;
              fill: #444;
            }
          </style>
        </defs>

        <!-- Connections -->
        <path class="connection" d="M 300 60 L 150 160" />
        <path class="connection" d="M 300 60 L 450 160" />
        <path class="connection" d="M 150 160 L 80 280" />
        <path class="connection" d="M 150 160 L 220 280" />

        <!-- Root Node -->
        <circle class="node-circle" cx="300" cy="60" r="50" />
        <text
          class="node-text"
          x="300"
          y="52"
          text-anchor="middle"
          font-weight="bold"
        >
          Root
        </text>
        <text class="label-text" x="300" y="66" text-anchor="middle">
          c ≈ (4.75, 6.25)
        </text>
        <text class="label-text" x="300" y="80" text-anchor="middle">
          r ≈ 4.26
        </text>

        <!-- Left Ball Node -->
        <circle class="node-circle" cx="150" cy="160" r="50" />
        <text
          class="node-text"
          x="150"
          y="152"
          text-anchor="middle"
          font-weight="bold"
        >
          Ball
        </text>
        <text class="label-text" x="150" y="166" text-anchor="middle">
          c ≈ (3.67, 5.33)
        </text>
        <text class="label-text" x="150" y="180" text-anchor="middle">
          r ≈ 3.3
        </text>
        <text class="point-text" x="150" y="220" text-anchor="middle">
          (2,5), (3,8), (6,3)
        </text>

        <!-- Right Leaf Node -->
        <circle class="leaf-circle" cx="450" cy="160" r="45" />
        <text
          class="node-text"
          x="450"
          y="152"
          text-anchor="middle"
          font-weight="bold"
        >
          Leaf
        </text>
        <text class="label-text" x="450" y="166" text-anchor="middle">
          (8, 9)
        </text>
        <text class="label-text" x="450" y="180" text-anchor="middle">
          r = 0
        </text>

        <!-- Left-Left Ball Node -->
        <circle class="node-circle" cx="80" cy="300" r="45" />
        <text
          class="node-text"
          x="80"
          y="292"
          text-anchor="middle"
          font-weight="bold"
        >
          Ball
        </text>
        <text class="label-text" x="80" y="306" text-anchor="middle">
          (...)
        </text>
        <text class="point-text" x="80" y="330" text-anchor="middle">
          (2,5), (3,8)
        </text>

        <!-- Left-Right Leaf Node -->
        <circle class="leaf-circle" cx="220" cy="300" r="45" />
        <text
          class="node-text"
          x="220"
          y="292"
          text-anchor="middle"
          font-weight="bold"
        >
          Leaf
        </text>
        <text class="label-text" x="220" y="306" text-anchor="middle">
          (6, 3)
        </text>
        <text class="label-text" x="220" y="320" text-anchor="middle">
          r = 0
        </text>
      </svg>
      <p>
        <strong>Key Observation:</strong> This tree is unbalanced, the outlier
        \((8, 9)\) is isolated at depth 1, while the dense cluster is pushed
        deeper. This asymmetry is actually beneficial for nearest-neighbor
        search: isolated outliers are quickly determined not to be neighbors,
        allowing aggressive pruning of their subtrees.
      </p>

      <h4>Nearest-Neighbor Search: Triangle Inequality Pruning</h4>
      <p>
        Given query point \(q\), the search maintains the current best distance
        \(D_{\text{best}}\) and uses the triangle inequality to prune entire
        subtrees.
      </p>
      <p><strong>Algorithm: BallTree NN Search</strong></p>
      <ol>
        <li>
          At node with ball \((c, r)\), compute lower bound: \(d_{\text{lb}} =
          \max(0, d(q, c) - r)\).
        </li>
        <li>
          If \(d_{\text{lb}} \ge D_{\text{best}}\): Prune this entire subtree
          (no point inside can be closer).
        </li>
        <li>Otherwise, continue.</li>
      </ol>
      <p>
        <strong>Traversal Order:</strong> Prioritize the child whose center is
        closer to \(q\) (best-first search).
      </p>
      <p>
        At leaf node: Compute exact distances to all points, update
        \(D_{\text{best}}\).
      </p>

      <p><strong>Example Query: \(q = (5, 6)\)</strong></p>
      <ul>
        <li>
          <strong>Step 1 (Root):</strong> \(d(q, \text{center}) \approx 0.35\).
          Lower bound \(0.35 - 4.26 < 0\). Cannot prune. Visit Left Child first
          (closer).
        </li>
        <li>
          <strong>Step 2 (Left Child):</strong> Cannot prune. Recurse.
          Eventually find \((3, 8)\) at distance \(\sqrt{8} \approx 2.83\).
          Update \(D_{\text{best}} = 2.83\).
        </li>
        <li>
          <strong>Step 3 (Backtrack to Right Child):</strong> Leaf \((8, 9)\).
          <br />Distance to ball center: \(d(q, (8,9)) \approx 4.24\).
          <br />Lower bound: \(4.24 - 0 = 4.24\). <br />Since \(4.24 \ge 2.83\)
          (\(D_{\text{best}}\)), Prune this subtree entirely.
        </li>
      </ul>
      <p>
        <strong>Result:</strong> We safely skipped examining the outlier node
        \((8, 9)\) after finding a good candidate in the dense cluster.
      </p>

      <h4>Pruning Condition: The Mathematical Core</h4>
      <p>
        The lower bound comes directly from the triangle inequality. For any
        point \(p\) in the ball:
      </p>
      <p class="responsive-math">
        \[ d(q, p) \ge |d(q, c) - d(p, c)| \ge |d(q, c) - r_{\max}| = d(q, c) -
        r \]
      </p>
      <p>
        Since \(d(p, c) \le r\) by definition, the worst-case (minimum) distance
        from \(q\) to any point in the ball is:
      </p>
      <p class="responsive-math">\[ d_{\text{lb}} = \max(0, d(q, c) - r) \]</p>
      <p>
        If \(d_{\text{lb}} > D_{\text{best}}\), every point in the ball is
        strictly farther than the current best candidate; pruning is safe and
        optimal.
      </p>

      <h4>Advanced: Optimization via PCA (Ball*-tree)</h4>
      <p>
        The standard "farthest-point" construction is simple but can lead to
        unbalanced trees. A more robust approach, known as Ball-tree*, uses
        Principal Component Analysis (PCA) to determine splits.
      </p>
      <ul>
        <li>
          <strong>The Logic:</strong> Compute the covariance matrix of the
          node's points and find the first principal component (direction of
          maximum variance). Project points onto this axis and split at the
          median.
        </li>
        <li>
          <strong>Result:</strong> A hyperplane perpendicular to the principal
          axis. This captures the data's natural geometry while maintaining
          better balance than farthest-point heuristics.
        </li>
        <li>
          <strong>Trade-off:</strong> Construction complexity rises to \(O(D^2
          \cdot N)\), but queries are faster due to tighter balls. [arxiv:1]
        </li>
      </ul>

      <h4>Strengths and Limitations</h4>
      <p><strong>Strengths</strong></p>
      <ul>
        <li>
          <strong>High-Dimensional Robustness:</strong> Superior performance
          when \(D \gtrsim 20\), especially when intrinsic dimensionality is
          low.
        </li>
        <li>
          <strong>Metric Flexibility:</strong> Supports any metric satisfying
          the triangle inequality (Euclidean, Manhattan, Cosine, Haversine).
        </li>
        <li>
          <strong>Isotropic Pruning:</strong> Spherical bounds are natural for
          distance-based queries and eliminate entire neighborhoods uniformly.
        </li>
      </ul>
      <p><strong>Limitations</strong></p>
      <ul>
        <li>
          <strong>Slower Construction:</strong> Building is generally slower
          than axis-aligned methods due to the cost of distance and/or PCA
          calculations.
        </li>
        <li>
          <strong>Higher Memory Usage:</strong> Storing center vectors and radii
          for every node adds overhead compared to storing simple scalar split
          values.
        </li>
        <li>
          <strong>Variable Tree Depth:</strong> Without PCA balancing, depth is
          not guaranteed to be logarithmic, which can affect worst-case
          performance.
        </li>
      </ul>

      <h4>Takeaway: BallTree as Metric Generalist</h4>
      <p>
        The BallTree represents a shift from geometric space-partitioning to
        metric-based pruning. Its fundamental operation is asking "how far from
        a center?" rather than "which side of a boundary?".
      </p>
      <p><strong>When to Use BallTree:</strong></p>
      <ul>
        <li>High-dimensional data (e.g., neural embeddings, text vectors).</li>
        <li>Non-Euclidean metrics (e.g., Haversine distance).</li>
        <li>Isotropic clusters where spherical bounds are tight.</li>
        <li>
          Datasets with low intrinsic dimensionality in high ambient space.
        </li>
      </ul>

      <h2 id="strtree">4. STRtree: The Sort-Tile-Recursive R-Tree Packer</h2>
      <p>
        The STRtree (Sort-Tile-Recursive tree) represents a paradigm shift from
        the hierarchical decomposition of KDTree and BallTree to the
        bulk-loading or packing of spatial objects. Unlike KDTree's recursive
        splits and BallTree's metric partitioning, STRtree explicitly optimizes
        for static geospatial data, polygons, line segments, and extended
        objects, by grouping them into hierarchically nested bounding boxes.
        This makes it the de facto standard in Geographic Information Systems
        (GIS) for indexing roads, buildings, and other real-world geometries.
      </p>

      <h4>Core Concept: Object Grouping via Minimum Bounding Rectangles</h4>
      <p>An R-tree is a height-balanced multi-way tree where:</p>
      <ul>
        <li>
          Leaf nodes store Minimum Bounding Rectangles (MBRs) of actual spatial
          objects (e.g., road line segments, building footprints).
        </li>
        <li>
          Internal nodes store MBRs that enclose all MBRs of their child nodes.
        </li>
        <li>
          Bounding boxes can overlap between siblings (unlike KDTree's disjoint
          partitions).
        </li>
      </ul>
      <p>
        The MBR of a set of objects is the smallest axis-aligned rectangle that
        fully contains all of them:
      </p>
      <p class="responsive-math">
        \[ \text{MBR}(S) = [\min_i x_{\min,i}, \max_i x_{\max,i}] \times [\min_i
        y_{\min,i}, \max_i y_{\max,i}] \]
      </p>

      <h4>STRtree vs. Standard R-tree: The Key Differences</h4>
      <p>
        A standard R-tree is built dynamically via insertions: each new object
        is placed in the leaf that causes the smallest MBR enlargement. Over
        time, with many updates, nodes can become fragmented and overlap
        heavily, degrading query performance. STRtree is built bottom-up in a
        single pass, using a bulk-loading algorithm called Sort-Tile-Recursive.
        The core insight:
      </p>

      <div class="responsive-table-container">
        <table border="1" cellpadding="8" cellspacing="0">
          <thead>
            <tr>
              <th>Aspect</th>
              <th>Standard R-tree</th>
              <th>STRtree</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td><strong>Construction</strong></td>
              <td>Dynamic insertion (top-down)</td>
              <td>Bulk loading (bottom-up)</td>
            </tr>
            <tr>
              <td><strong>Optimization Goal</strong></td>
              <td>Minimize MBR enlargement per insertion</td>
              <td>Minimize overlap and dead space globally</td>
            </tr>
            <tr>
              <td><strong>Space Utilization</strong></td>
              <td>50–70% of nodes filled</td>
              <td>95–100% of nodes filled</td>
            </tr>
            <tr>
              <td><strong>Node Overflow</strong></td>
              <td>Triggers expensive splits</td>
              <td>Never occurs (pre-computed)</td>
            </tr>
            <tr>
              <td><strong>Overlap</strong></td>
              <td>High (objects scattered across branches)</td>
              <td>Low (spatially coherent grouping)</td>
            </tr>
            <tr>
              <td><strong>Query Performance</strong></td>
              <td>Good for distributed data, degrades over updates</td>
              <td>Optimal for static data</td>
            </tr>
            <tr>
              <td><strong>Update Cost</strong></td>
              <td>\(O(\log N)\) per insertion</td>
              <td>\(O(N)\) to rebuild tree</td>
            </tr>
          </tbody>
        </table>
      </div>
      <p>
        <strong>When to use STRtree:</strong> Static or slowly-changing
        geospatial datasets (e.g., city boundaries, road networks).
        <strong>When to use standard R-tree:</strong> Frequently updated data
        (e.g., moving vehicles, real-time sensor positions).
      </p>

      <h4>The Sort-Tile-Recursive Algorithm</h4>
      <p>
        The STRtree construction algorithm works in three phases: sort, tile,
        and recursively build.
      </p>
      <p><strong>Algorithm: Construct STRtree (Bulk-Load)</strong></p>
      <ol>
        <li>
          <strong>Input:</strong> Set of spatial objects \(O = \{o_1, \ldots,
          o_N\}\), each with MBR \(b_i\).
        </li>
        <li>
          <strong>Output:</strong> STRtree with leaf capacity \(C\) (typically
          30–50 objects per leaf).
        </li>
        <li>
          <strong>Phase 1: Sort</strong>
          <ul>
            <li>Compute MBRs for all objects.</li>
            <li>Sort all MBRs by their \(x_{\min}\) coordinate (left edge).</li>
          </ul>
        </li>
        <li>
          <strong>Phase 2: Tile</strong>
          <ul>
            <li>Partition sorted MBRs into vertical slabs.</li>
            <li>Number of slabs: \(S = \lceil \sqrt{N/C} \rceil\).</li>
            <li>Each slab contains approximately \(N/S\) objects.</li>
            <li>
              Within each slab, sort by \(y_{\min}\) coordinate (bottom edge) to
              create row-based grouping.
            </li>
          </ul>
        </li>
        <li>
          <strong>Phase 3: Recursive Build</strong>
          <ul>
            <li>
              Within each slab, group objects into horizontal tiles of size
              ~\(C\).
            </li>
            <li>Create a leaf node for each tile, computing its MBR.</li>
            <li>
              Recursively apply the algorithm to the set of all leaf MBRs to
              create the next level of internal nodes.
            </li>
            <li>Continue until a single root node.</li>
          </ul>
        </li>
      </ol>

      <h4>Concrete Example: 8 Points in 2D</h4>
      <p>
        Consider 8 objects with centers: \(O = \{(1,1), (2,8), (3,2), (4,7),
        (5,3), (6,6), (7,1), (8,9)\}\). Assume leaf capacity \(C=2\).
      </p>
      <ol>
        <li>
          <strong>Step 1: Sort by x-coordinate</strong><br />Already in order:
          \((1,1), (2,8), (3,2), (4,7), (5,3), (6,6), (7,1), (8,9)\).
        </li>
        <li>
          <strong>Step 2: Compute and partition into slabs</strong><br />\(S =
          \lceil \sqrt{8/2} \rceil = \lceil 2 \rceil = 2\) slabs.<br />Objects
          per slab: \(N/S = 8/2 = 4\) objects.<br />Slab 1 (\(x \in [1,5]\)):
          \((1,1), (2,8), (3,2), (4,7)\)<br />Slab 2 (\(x \in [5,8]\)): \((5,3),
          (6,6), (7,1), (8,9)\)
        </li>
        <li>
          <strong>Step 3: Sort within slabs by y-coordinate</strong><br />Slab
          1: \((1,1), (3,2), (4,7), (2,8)\)<br />Slab 2: \((7,1), (5,3), (6,6),
          (8,9)\)
        </li>
        <li>
          <strong>Step 4: Create leaf tiles</strong><br />Within each slab,
          partition into groups of size \(C=2\):<br />
          <ul>
            <li>
              Slab 1, Tile A: \((1,1), (3,2)\) → MBR: \([1,3] \times [1,2]\)
            </li>
            <li>
              Slab 1, Tile B: \((4,7), (2,8)\) → MBR: \([2,4] \times [7,8]\)
            </li>
            <li>
              Slab 2, Tile C: \((7,1), (5,3)\) → MBR: \([5,7] \times [1,3]\)
            </li>
            <li>
              Slab 2, Tile D: \((6,6), (8,9)\) → MBR: \([6,8] \times [6,9]\)
            </li>
          </ul>
        </li>
        <li>
          <strong>Step 5: Build next level</strong><br />Now recursively apply
          STRtree to the 4 leaf MBRs. With \(S = \lceil\sqrt{4/2}\rceil = 1\)
          slab, we group all 4 leaves into a single internal node:<br />Root:
          MBR: \([1,8] \times [1,9]\), children: Tiles A, B, C, D.
        </li>
      </ol>
      <p>Resulting tree structure:</p>
      <svg
        width="600"
        height="400"
        viewBox="0 0 600 400"
        xmlns="http://www.w3.org/2000/svg"
      >
        <!-- Define styles -->
        <defs>
          <style>
            .root-rect {
              fill: #fce4ec;
              stroke: #c2185b;
              stroke-width: 3;
            }
            .tile-rect {
              fill: #e1f5fe;
              stroke: #0277bd;
              stroke-width: 2;
            }
            .connection {
              stroke: #666;
              stroke-width: 2;
              fill: none;
            }
            .node-text {
              font-family: Arial, sans-serif;
              font-size: 13px;
              fill: #333;
              font-weight: bold;
            }
            .range-text {
              font-family: monospace;
              font-size: 11px;
              fill: #666;
            }
          </style>
        </defs>

        <!-- Connections -->
        <path class="connection" d="M 300 100 L 80 240" />
        <path class="connection" d="M 300 100 L 220 240" />
        <path class="connection" d="M 300 100 L 380 240" />
        <path class="connection" d="M 300 100 L 520 240" />

        <!-- Root Node -->
        <rect class="root-rect" x="250" y="50" width="100" height="70" rx="5" />
        <text class="node-text" x="300" y="75" text-anchor="middle">Root</text>
        <text class="range-text" x="300" y="92" text-anchor="middle">
          [1,8]×[1,9]
        </text>

        <!-- Tile-A -->
        <rect class="tile-rect" x="30" y="220" width="100" height="70" rx="5" />
        <text class="node-text" x="80" y="245" text-anchor="middle">
          Tile-A
        </text>
        <text class="range-text" x="80" y="262" text-anchor="middle">
          [1,3]×[1,2]
        </text>

        <!-- Tile-B -->
        <rect
          class="tile-rect"
          x="170"
          y="220"
          width="100"
          height="70"
          rx="5"
        />
        <text class="node-text" x="220" y="245" text-anchor="middle">
          Tile-B
        </text>
        <text class="range-text" x="220" y="262" text-anchor="middle">
          [2,4]×[7,8]
        </text>

        <!-- Tile-C -->
        <rect
          class="tile-rect"
          x="330"
          y="220"
          width="100"
          height="70"
          rx="5"
        />
        <text class="node-text" x="380" y="245" text-anchor="middle">
          Tile-C
        </text>
        <text class="range-text" x="380" y="262" text-anchor="middle">
          [5,7]×[1,3]
        </text>

        <!-- Tile-D -->
        <rect
          class="tile-rect"
          x="470"
          y="220"
          width="100"
          height="70"
          rx="5"
        />
        <text class="node-text" x="520" y="245" text-anchor="middle">
          Tile-D
        </text>
        <text class="range-text" x="520" y="262" text-anchor="middle">
          [6,8]×[6,9]
        </text>
      </svg>

      <h4>Complexity Analysis</h4>
      <ul>
        <li>
          <strong>Construction Time:</strong> \(O(N \log N + N \log_C N) = O(N
          \log N)\). Dominated by sorting.
        </li>
        <li>
          <strong>Space Utilization:</strong> Each leaf contains approximately
          \(C\) objects (95–100% full). No wasted space from node fragmentation.
        </li>
        <li>
          <strong>Query Time (Window Query):</strong> \(O(\log_C N + K)\) where
          \(K\) is the number of reported objects. The low overlap from STRtree
          packing means fewer branches are traversed, making queries faster than
          standard R-trees on static data.
        </li>
      </ul>

      <h4>Range Query: Pruning with Overlaps</h4>
      <p>
        Given a query window \(Q = [x_q, x'_q] \times [y_q, y'_q]\) (a
        rectangle), find all objects intersecting \(Q\).
      </p>
      <p><strong>Algorithm: STRtree Range Query</strong></p>
      <ol>
        <li>Start at root.</li>
        <li>For each child node with MBR \(M\):</li>
        <ul>
          <li>If \(M \cap Q \neq \emptyset\) (MBRs overlap), descend.</li>
          <li>Otherwise, prune entire subtree.</li>
        </ul>
        <li>At leaf nodes, test actual object geometries against \(Q\).</li>
      </ol>
      <p>Two rectangles intersect if:</p>
      <p class="responsive-math">
        \[ M \cap Q \neq \emptyset \iff x_{\min}(M) \le x'_q \text{ AND }
        x_{\max}(M) \ge x_q \text{ AND } y_{\min}(M) \le y'_q \text{ AND }
        y_{\max}(M) \ge y_q \]
      </p>

      <h4>Concrete Query Example</h4>
      <p>
        Using the tree from above, query window: \(Q = [2, 6] \times [2, 8]\).
      </p>
      <ul>
        <li>
          <strong>At root \([1,8] \times [1,9]\):</strong> Overlaps \(Q\)? Yes.
          Descend to all children.
        </li>
        <li>
          <strong>Check Tile-A \([1,3] \times [1,2]\):</strong> Overlaps \(Q\)?
          Yes. Check points: \((1,1)\) no, \((3,2)\) yes. Report \((3,2)\).
        </li>
        <li>
          <strong>Check Tile-B \([2,4] \times [7,8]\):</strong> Overlaps \(Q\)?
          Yes. Check points: \((4,7)\) yes, \((2,8)\) yes. Report both.
        </li>
        <li>
          <strong>Check Tile-C \([5,7] \times [1,3]\):</strong> Overlaps \(Q\)?
          Yes. Check points: \((7,1)\) no, \((5,3)\) yes. Report \((5,3)\).
        </li>
        <li>
          <strong>Check Tile-D \([6,8] \times [6,9]\):</strong> Overlaps \(Q\)?
          Yes. Check points: \((6,6)\) yes, \((8,9)\) no. Report \((6,6)\).
        </li>
      </ul>
      <p>
        <strong>Final result:</strong> Objects \((3,2), (4,7), (2,8), (5,3),
        (6,6)\) intersect the query window.
      </p>

      <h4>Tree Visualization</h4>
      <p>Here is an SVG representation of the constructed STRtree:</p>
      <svg
        width="850"
        height="450"
        viewBox="0 0 850 450"
        xmlns="http://www.w3.org/2000/svg"
        font-family="Arial, sans-serif"
      >
        <defs>
          <marker
            id="arrow"
            markerWidth="10"
            markerHeight="10"
            refX="9"
            refY="3"
            orient="auto"
            markerUnits="strokeWidth"
          >
            <path d="M0,0 L0,6 L9,3 z" fill="#555" />
          </marker>
          <style>
            .grid-line {
              stroke: #e0e0e0;
              stroke-width: 1;
            }
            .axis {
              stroke: #333;
              stroke-width: 2;
            }
            .label {
              font-size: 12px;
              fill: #555;
            }
            .title {
              font-size: 16px;
              font-weight: bold;
              fill: #333;
            }
            .mbr {
              fill-opacity: 0.2;
              stroke-width: 2;
            }
            .point {
              fill: #333;
              r: 4;
            }
            .point-label {
              font-size: 10px;
              fill: #333;
              font-weight: bold;
            }
            .query-box {
              fill: none;
              stroke: #ff0000;
              stroke-width: 2;
              stroke-dasharray: 5, 5;
            }

            /* Node Styles for Tree */
            .node-rect {
              fill: #fff;
              stroke-width: 2;
              rx: 5;
            }
            .node-text {
              font-size: 12px;
              font-weight: bold;
              text-anchor: middle;
              dominant-baseline: middle;
            }
            .mbr-text {
              font-size: 10px;
              fill: #666;
              text-anchor: middle;
            }
            .link {
              stroke: #555;
              stroke-width: 1.5;
              fill: none;
              marker-end: url(#arrow);
            }

            /* Color Coding Groups */
            .group-a {
              stroke: #2e7d32;
              fill: #2e7d32;
            } /* Green */
            .group-b {
              stroke: #1565c0;
              fill: #1565c0;
            } /* Blue */
            .group-c {
              stroke: #ef6c00;
              fill: #ef6c00;
            } /* Orange */
            .group-d {
              stroke: #6a1b9a;
              fill: #6a1b9a;
            } /* Purple */
          </style>
        </defs>

        <rect width="100%" height="100%" fill="#fafafa" />

        <g transform="translate(40, 40)">
          <text x="150" y="-15" class="title" text-anchor="middle">
            Spatial View (2D Map)
          </text>

          <g class="grid">
            <path
              d="M0,350 L350,350 M0,315 L350,315 M0,280 L350,280 M0,245 L350,245 M0,210 L350,210 M0,175 L350,175 M0,140 L350,140 M0,105 L350,105 M0,70 L350,70 M0,35 L350,35 M0,0 L350,0"
              class="grid-line"
            />
            <path
              d="M0,0 L0,350 M35,0 L35,350 M70,0 L70,350 M105,0 L105,350 M140,0 L140,350 M175,0 L175,350 M210,0 L210,350 M245,0 L245,350 M280,0 L280,350 M315,0 L315,350 M350,0 L350,350"
              class="grid-line"
            />
          </g>

          <line x1="0" y1="350" x2="350" y2="350" class="axis" />
          <line x1="0" y1="350" x2="0" y2="0" class="axis" />
          <text x="340" y="370" class="label">X</text>
          <text x="-25" y="10" class="label">Y</text>

          <rect x="70" y="70" width="140" height="210" class="query-box" />
          <text
            x="140"
            y="60"
            class="label"
            fill="#ff0000"
            text-anchor="middle"
          >
            Query Window
          </text>

          <rect x="35" y="280" width="70" height="35" class="mbr group-a" />
          <rect x="70" y="70" width="70" height="35" class="mbr group-b" />
          <rect x="175" y="245" width="70" height="70" class="mbr group-c" />
          <rect x="210" y="35" width="70" height="105" class="mbr group-d" />

          <circle cx="35" cy="315" class="point" />
          <text x="35" y="310" class="point-label" text-anchor="end">
            (1,1)
          </text>
          <circle cx="105" cy="280" class="point" />
          <text x="105" y="275" class="point-label">(3,2)</text>

          <circle cx="140" cy="105" class="point" />
          <text x="145" y="105" class="point-label">(4,7)</text>
          <circle cx="70" cy="70" class="point" />
          <text x="65" y="70" class="point-label" text-anchor="end">(2,8)</text>

          <circle cx="245" cy="315" class="point" />
          <text x="250" y="315" class="point-label">(7,1)</text>
          <circle cx="175" cy="245" class="point" />
          <text x="170" y="240" class="point-label" text-anchor="end">
            (5,3)
          </text>

          <circle cx="210" cy="140" class="point" />
          <text x="205" y="140" class="point-label" text-anchor="end">
            (6,6)
          </text>
          <circle cx="280" cy="35" class="point" />
          <text x="285" y="35" class="point-label">(8,9)</text>
        </g>

        <g transform="translate(450, 40)">
          <text x="180" y="-15" class="title" text-anchor="middle">
            Tree Structure
          </text>

          <g transform="translate(130, 30)">
            <rect
              x="-50"
              y="-20"
              width="100"
              height="40"
              class="node-rect"
              style="stroke: #333"
            />
            <text x="0" y="0" class="node-text">ROOT</text>
            <text x="0" y="35" class="mbr-text">[1,8] x [1,9]</text>
          </g>

          <path d="M 130 50 L 40 130" class="link" />
          <path d="M 130 50 L 100 130" class="link" />
          <path d="M 130 50 L 260 130" class="link" />
          <path d="M 130 50 L 320 130" class="link" />

          <g transform="translate(40, 150)">
            <rect
              x="-35"
              y="-20"
              width="70"
              height="40"
              class="node-rect group-a"
              style="fill-opacity: 0.1"
            />
            <text x="0" y="0" class="node-text" fill="#2e7d32">Tile A</text>
            <text x="0" y="35" class="mbr-text">[1,3] x [1,2]</text>
          </g>

          <g transform="translate(120, 150)">
            <rect
              x="-35"
              y="-20"
              width="70"
              height="40"
              class="node-rect group-b"
              style="fill-opacity: 0.1"
            />
            <text x="0" y="0" class="node-text" fill="#1565c0">Tile B</text>
            <text x="0" y="35" class="mbr-text">[2,4] x [7,8]</text>
          </g>

          <g transform="translate(240, 150)">
            <rect
              x="-35"
              y="-20"
              width="70"
              height="40"
              class="node-rect group-c"
              style="fill-opacity: 0.1"
            />
            <text x="0" y="0" class="node-text" fill="#ef6c00">Tile C</text>
            <text x="0" y="35" class="mbr-text">[5,7] x [1,3]</text>
          </g>

          <g transform="translate(320, 150)">
            <rect
              x="-35"
              y="-20"
              width="70"
              height="40"
              class="node-rect group-d"
              style="fill-opacity: 0.1"
            />
            <text x="0" y="0" class="node-text" fill="#6a1b9a">Tile D</text>
            <text x="0" y="35" class="mbr-text">[6,8] x [6,9]</text>
          </g>

          <g transform="translate(0, 260)">
            <rect x="0" y="0" width="360" height="90" fill="#f5f5f5" rx="5" />
            <text x="10" y="20" font-weight="bold" font-size="12">
              Legend & Logic:
            </text>
            <text x="10" y="40" font-size="11">
              1. Objects sorted by X, then Y (Slab method).
            </text>
            <text x="10" y="55" font-size="11">
              2. Colored boxes = Leaf Nodes (MBRs).
            </text>
            <text x="10" y="70" font-size="11">
              3. Red Dashed Box = Query Window.
            </text>
          </g>
        </g>
      </svg>
      <h4>Strengths and Limitations</h4>
      <p><strong>Strengths</strong></p>
      <ul>
        <li>
          <strong>Optimal space utilization:</strong> 95–100% node occupancy for
          static data.
        </li>
        <li>
          <strong>Minimal overlap:</strong> Sorted grouping creates spatially
          coherent clusters, reducing branch exploration during queries.
        </li>
        <li>
          <strong>Fast construction:</strong> Single-pass \(O(N \log N)\)
          bulk-load is much faster than incremental insertion on large datasets.
        </li>
        <li>
          <strong>Proven in production:</strong> Industry standard in GIS
          systems (PostGIS, Shapely, QGIS).
        </li>
        <li>
          Excellent query performance on static geospatial data (roads,
          buildings, administrative boundaries).
        </li>
      </ul>
      <p><strong>Limitations</strong></p>
      <ul>
        <li>
          <strong>No dynamic updates:</strong> Any insertion/deletion requires
          rebuilding the entire tree (\(O(N)\) cost). Practical workaround:
          maintain a "delta tree" of recent changes and merge periodically.
        </li>
        <li>
          <strong>Only for axis-aligned objects:</strong> Cannot handle rotated
          rectangles or more complex shapes without reorienting to axis-aligned
          MBRs.
        </li>
        <li>
          <strong>Fixed leaf capacity:</strong> Must be tuned for disk block
          size and object size. Suboptimal capacity reduces performance.
        </li>
        <li>
          <strong>Data distribution dependent:</strong> Skewed or highly
          clustered data can still cause overlap despite sorting. (Advanced
          variants like R*-tree use more sophisticated splitting heuristics.)
        </li>
      </ul>

      <h4>Takeaway: STRtree as the Geospatial Standard</h4>
      <p>
        The STRtree bridges the gap between theoretical elegance (KDTree,
        BallTree) and practical necessity. By accepting that geospatial data is
        often static or slow-changing and high-dimensional (polygons with
        multiple vertices), STRtree sacrifices dynamic insertion for massive
        query efficiency gains.
      </p>
      <p>
        <strong>Key insight:</strong> The Sort-Tile-Recursive algorithm encodes
        geographic intuition, sort objects left-to-right (longitude), then
        bottom-to-top (latitude), into a tree structure that reflects natural
        spatial clustering.
      </p>
      <p>
        <strong>When to use STRtree:</strong> City datasets, road networks,
        building registries, boundaries (95% of real-world GIS use cases).
      </p>
      <p><strong>When to use alternatives:</strong></p>
      <ul>
        <li>
          <strong>KDTree:</strong> Low-dimensional Euclidean point clouds (\(d <
          10\)).
        </li>
        <li>
          <strong>BallTree:</strong> High-dimensional metric spaces with
          frequent queries but rare updates.
        </li>
        <li>
          <strong>Standard R-tree:</strong> Datasets with frequent updates,
          where rebuild cost is prohibitive.
        </li>
      </ul>

      <h2 id="comparison">5. Practical Comparison & Benchmarks</h2>
      <p>
        While the theoretical differences between spatial trees are complex, the
        choice for real-world applications typically follows a clear decision
        path based on dimensionality, data type, and update frequency.
      </p>

      <h4>Performance Comparison Matrix</h4>
      <p>
        This matrix consolidates theoretical Big-O complexity with real-world
        benchmark observations.
      </p>

      <div class="responsive-table-container">
        <table border="1" cellpadding="8" cellspacing="0">
          <thead>
            <tr>
              <th>Feature</th>
              <th>KDTree</th>
              <th>BallTree</th>
              <th>STRtree (R-tree variant)</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td><strong>Ideal Data</strong></td>
              <td>Points in low dimensions (\(d \le 10\))</td>
              <td>High-dimensional points or non-Euclidean metrics</td>
              <td>Extended objects (polygons, lines)</td>
            </tr>
            <tr>
              <td><strong>Build Time</strong></td>
              <td>Fastest (\(O(N \log N)\))<br />~10ms for 1M points</td>
              <td>Moderate (\(O(N \log N)\))<br />~50ms for 1M points</td>
              <td>Slowest (\(O(N \log N)\))<br />~100ms for 1M rectangles</td>
            </tr>
            <tr>
              <td><strong>Query Time</strong></td>
              <td>Fast (\(O(\log N)\)) in low dims<br />~0.5ms per query</td>
              <td>
                Robust (\(O(\log N)\)) in high dims<br />~1.2ms (low dim) to 8ms
                (high dim)
              </td>
              <td>Fast for window queries<br />~50ms per window query</td>
            </tr>
            <tr>
              <td><strong>High-Dim Behavior</strong></td>
              <td>Degrades to \(O(N)\) if \(d > 20\)</td>
              <td>Resilient; adapts to intrinsic dimensionality</td>
              <td>N/A (rarely used for high-dim vectors)</td>
            </tr>
            <tr>
              <td><strong>Memory Overhead</strong></td>
              <td>Low (~70% occupancy)</td>
              <td>Medium (stores centroids/radii)</td>
              <td>High (stores MBRs)</td>
            </tr>
            <tr>
              <td><strong>Dynamic Updates</strong></td>
              <td>Efficient (\(O(\log N)\) insertion)</td>
              <td>Efficient (\(O(\log N)\) insertion)</td>
              <td>Expensive (\(O(N)\) rebuild required)</td>
            </tr>
          </tbody>
        </table>
      </div>

      <h4>Use-Case Decision Framework</h4>

      <p>
        <strong
          >1. Low-Dimensional Point Data (\(d \lesssim 10\)) \(\rightarrow\)
          KDTree</strong
        >
      </p>
      <p>
        KDTree is the standard for low-dimensional Euclidean space due to its
        lightweight construction and memory efficiency. It is ideal for 3D
        graphics (ray tracing), 2D GIS points (ATMs, amenities), and robotic
        configuration spaces.
      </p>
      <p>
        <strong>Benchmark:</strong> For uniformly distributed 3D data (1M
        points), KDTree queries average ~0.5–2 ms, significantly faster than
        BallTree due to lower constant overhead factors.
      </p>

      <p>
        <strong
          >2. High-Dimensional or Non-Euclidean Data (\(d > 20\))
          \(\rightarrow\) BallTree</strong
        >
      </p>
      <p>
        In high dimensions, the volume of the corners in a hypercube becomes
        dominant, rendering KDTree's axis-aligned splits ineffective (the "curse
        of dimensionality"). BallTree clusters points in hyperspheres, allowing
        it to prune search spaces based on intrinsic dimensionality rather than
        ambient coordinates.
      </p>
      <p>
        <strong>Key Capability:</strong> Supports custom metrics like Cosine
        (text similarity), Haversine (geospatial lat/lon), and Jaccard.
      </p>
      <p>
        <strong>Benchmark:</strong> For 100K text embeddings (\(d=300\)),
        BallTree maintains ~5–20 ms per query, whereas KDTree degrades to
        brute-force speeds (~500+ ms).
      </p>

      <pre><code class="language-python">
    from sklearn.neighbors import NearestNeighbors

    # BallTree is preferred for high-dim or custom metrics
    # Note: 'algorithm="auto"' in scikit-learn handles this selection automatically
    nbrs = NearestNeighbors(n_neighbors=5, algorithm='ball_tree', metric='haversine')
    nbrs.fit(X_lat_lon)
    distances, indices = nbrs.kneighbors(query_point)
      </code></pre>

      <p>
        <strong
          >3. Static Geospatial Geometries (Polygons/Lines) \(\rightarrow\)
          STRtree</strong
        >
      </p>
      <p>
        STRtree (Sort-Tile-Recursive) is the industry standard for indexing
        extended objects like roads, administrative boundaries, and building
        footprints. Unlike KD/Ball trees, it indexes bounding boxes rather than
        points, making it the only viable choice for "Which polygon contains
        this point?" or "Which roads intersect this window?" queries.
      </p>
      <p>
        <strong>Warning:</strong> STRtree is static. Adding a single geometry
        requires a full rebuild (\(O(N)\)), making it unsuitable for streaming
        data.
      </p>

      <pre><code class="language-python">
    from shapely.strtree import STRtree

    # Shapely 2.0+ Pattern: Operations return indices, not geometries
    tree = STRtree(geometries)

    # Query: Find indices of geometries intersecting the query_box
    # This is significantly faster than checking all geometries (~50ms vs 2000ms)
    indices = tree.query(query_box)
    matching_geoms = [geometries[i] for i in indices]
      </code></pre>

      <p>
        <strong
          >4. Dynamic or Streaming Data \(\rightarrow\) KDTree /
          BallTree</strong
        >
      </p>
      <p>
        If your data changes frequently (e.g., live drone tracking, ride-sharing
        fleets), avoid STRtree. Use KDTree or BallTree, which support efficient
        \(O(\log N)\) insertions. For geospatial apps requiring updates, a
        common hybrid approach is to map GPS coordinates to a KDTree for
        proximity checks while keeping static map layers in an STRtree.
      </p>

      <p><strong>5. Anti-Patterns: When NOT to Use a Spatial Index</strong></p>
      <ul>
        <li>
          <strong>Tiny Datasets (\(N < 1000\)):</strong> The overhead of
          building and traversing the tree exceeds the cost of a simple linear
          scan (Brute Force).
        </li>
        <li>
          <strong>Single-Shot Queries:</strong> If you only need to perform one
          query, building an index (\(O(N \log N)\)) is slower than just
          calculating distances once (\(O(N)\)).
        </li>
        <li>
          <strong>Wrong Topology:</strong> Using KDTree for geospatial lat/lon
          data can yield incorrect results near the poles or meridian
          wrap-around; BallTree with metric='haversine' is correct.
        </li>
      </ul>

      <h4>Language & Library Ecosystem</h4>
      <div class="responsive-table-container">
        <table border="1" cellpadding="8" cellspacing="0">
          <thead>
            <tr>
              <th>Language</th>
              <th>Points (KD/Ball)</th>
              <th>Polygons (R-tree/STR)</th>
              <th>Notes</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td><strong>Python</strong></td>
              <td>scikit-learn</td>
              <td>shapely, rtree</td>
              <td>
                Scikit-learn's <code>algorithm='auto'</code> intelligently swaps
                KD/Ball/Brute.
              </td>
            </tr>
            <tr>
              <td><strong>Java</strong></td>
              <td>Custom / ELKI</td>
              <td>JTS (STRtree)</td>
              <td>JTS is the backend for many JVM spatial tools.</td>
            </tr>
            <tr>
              <td><strong>C++</strong></td>
              <td>NanoFlann, Boost</td>
              <td>Boost.Geometry</td>
              <td>NanoFlann is highly optimized for 3D point clouds.</td>
            </tr>
            <tr>
              <td><strong>SQL</strong></td>
              <td>N/A</td>
              <td>PostGIS (GiST)</td>
              <td>GiST implements R-tree logic on disk.</td>
            </tr>
          </tbody>
        </table>
      </div>

      <div
        class="references-section"
        style="margin-top: 40px; border-top: 1px solid #eee; padding-top: 20px"
      >
        <h3>References & Further Reading</h3>
        <ul style="list-style-type: none; padding-left: 0">
          <li style="margin-bottom: 15px">
            <a
              href="http://www.gitta.info/SpatPartitio/en/text/SpatPartitio.pdf"
              target="_blank"
              style="font-weight: bold; color: #2c3e50; text-decoration: none"
              >Spatial Partitioning and Indexing</a
            ><br />
            <span style="color: #666; font-size: 0.95em"
              >A comprehensive overview of regular (Grid, Quadtree) and
              object-oriented (Binary tree, R-tree) decomposition methods for
              spatial data access.</span
            >
          </li>

          <li style="margin-bottom: 15px">
            <a
              href="https://d-nb.info/988097362/34"
              target="_blank"
              style="font-weight: bold; color: #2c3e50; text-decoration: none"
              >The Priority R-Tree: A Practically Efficient and Worst-Case
              Optimal R-Tree</a
            ><br />
            <span style="color: #666; font-size: 0.95em"
              >Investigates bulk-loading strategies like the Sort-Tile-Recursive
              (STR) algorithm to optimize R-tree structures for static
              geospatial datasets.</span
            >
          </li>

          <li style="margin-bottom: 15px">
            <a
              href="https://arxiv.org/pdf/1210.6122"
              target="_blank"
              style="font-weight: bold; color: #2c3e50; text-decoration: none"
              >Performance Evaluation: Ball-Tree and KD-Tree in the context of
              MST</a
            ><br />
            <span style="color: #666; font-size: 0.95em"
              >Explores the theoretical limits of space-partitioning structures
              and how high intrinsic dimensionality affects KD-tree versus
              Ball-tree performance.</span
            >
          </li>

          <li style="margin-bottom: 15px">
            <a
              href="https://www.ri.cmu.edu/pub_files/pub1/moore_andrew_1991_1/moore_andrew_1991_1.pdf"
              target="_blank"
              style="font-weight: bold; color: #2c3e50; text-decoration: none"
              >An into ductory tutorial on kd-trees</a
            ><br />
            <span style="color: #666; font-size: 0.95em"
              >Andrew Moore's foundational thesis on KD-trees, introducing
              efficient nearest-neighbor search algorithms and pruning
              strategies that underpin modern implementations.</span
            >
          </li>

          <li style="margin-bottom: 15px">
            <a
              href="https://arxiv.org/pdf/1511.0628"
              target="_blank"
              style="font-weight: bold; color: #2c3e50; text-decoration: none"
              >Ball*-tree: Efficient spatial indexing for constrained
              nearest-neighbor search in metric spaces</a
            ><br />
            <span style="color: #666; font-size: 0.95em"
              >Discusses advanced construction techniques for BallTrees,
              including PCA-based splitting, to handle high-dimensional metric
              spaces more effectively.</span
            >
          </li>
        </ul>
      </div>

      <div id="disqus_thread"></div>
      <script>
        var disqus_config = function () {
          this.page.url =
            "https://www.francescosannicola.com/articles/spatial-indexing-trees.html";
          this.page.identifier = "spatial-indexing-trees";
          this.page.title =
            "Spatial Indexing Trees: KDTree, BallTree, and STRtree";
        };

        (function () {
          var d = document,
            s = d.createElement("script");
          s.src = "https://francescosannicola.disqus.com/embed.js";
          s.setAttribute("data-timestamp", +new Date());
          (d.head || d.body).appendChild(s);
        })();
      </script>
      <noscript
        >Please enable JavaScript to view the
        <a href="https://disqus.com/?ref_noscript"
          >comments powered by Disqus.</a
        ></noscript
      >
    </div>

    <button
      id="backToTopButton"
      onclick="scrollToTop()"
      style="font-size: 24px; padding: 10px 20px"
    >
      <i class="fa fa-arrow-up"></i>
    </button>

    <script>
      let isDarkMode = localStorage.getItem("darkMode") === "true";

      function applyDarkMode(dark) {
        const darkModeToggle = document.getElementById("darkModeToggle");
        const elements = [
          document.body,
          ...document.querySelectorAll(
            ".main-container, .info-container, .projects-container, .article-container, .link-container, .accordion, .code"
          ),
        ];

        isDarkMode = dark;
        localStorage.setItem("darkMode", dark);

        elements.forEach((element) => {
          if (dark) {
            element.classList.add("dark-mode");
          } else {
            element.classList.remove("dark-mode");
          }
        });

        if (darkModeToggle) {
          darkModeToggle.checked = dark;
        }
      }

      document.addEventListener("DOMContentLoaded", () => {
        const darkModeToggle = document.getElementById("darkModeToggle");
        applyDarkMode(isDarkMode);

        darkModeToggle.addEventListener("change", (e) => {
          applyDarkMode(e.target.checked);
        });
      });

      if (isDarkMode) {
        applyDarkMode(true);
      }

      function scrollToTop() {
        document.body.scrollTop = 0;
        document.documentElement.scrollTop = 0;
      }
      window.addEventListener("scroll", () => {
        const button = document.getElementById("backToTopButton");
        if (window.scrollY > 500) {
          button.style.display = "block";
        } else {
          button.style.display = "none";
        }
      });
    </script>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js"></script>
  </body>
</html>
